{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"private_outputs":true,"provenance":[{"file_id":"1zeDpeTQMa1xCry2XZhLWitzgaTZje_hZ","timestamp":1628777650761},{"file_id":"1V52nlSi9sDoKzdZLXvPY8toSvFIT0ZSb","timestamp":1628686665442},{"file_id":"1JSLkpBTh4dfy1dGGsCMkNUtXLifcC5yc","timestamp":1628175215071},{"file_id":"https://github.com/saeed1262/MoVi-Toolbox/blob/master/MoCap/tutorial_python.ipynb","timestamp":1628174784865}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"N8M1ix43tg8F"},"source":["## Using MoVi data in Python"]},{"cell_type":"markdown","metadata":{"id":"hqfwqhFUtg8H"},"source":["MoVi dataset is originally provided as `.mat` format.  \n","We provide some utility functions to make it easy reading MoVi files in Python environment"]},{"cell_type":"code","metadata":{"id":"5t8jo0cRuRQU"},"source":["# Import Libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import math\n","import time\n","import nltk\n","import random\n","import collections\n","import glob\n","\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn import functional as F\n","from pathlib import Path\n","from numpy.random import randint\n","from sklearn.model_selection import train_test_split\n","\n","%load_ext autoreload\n","%autoreload 2\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xRyVhgYl77Dz"},"source":["**SUBJECT 10**"]},{"cell_type":"code","metadata":{"id":"oNqUFTzV-cDZ"},"source":["#looking at just one participant\n","data = pd.read_csv('/content/drive/MyDrive/Neuromatch/preproc/PP_10_I1.csv')\n","for col in data.columns:\n","    print(col)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vjSNkDYz_Pre"},"source":["#input \n","input = data[['RightForeArm_rot_0',\n","              'RightForeArm_rot_1',\n","              'RightForeArm_rot_2',\n","              'RightForeArm_rot_3',\n","              'RightForeArm_rot_4',\n","              'RightForeArm_rot_5',\n","              'RightForeArm_rot_6',\n","              'RightForeArm_rot_7',\n","              'RightForeArm_rot_8',\n","              \n","              'RightForeArm_acc_0',\n","              'RightForeArm_acc_1',\n","              'RightForeArm_acc_2',]]\n","\n","input.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UEQTmHdsBtd6"},"source":["#output\n","\n","output = data[['RightShoulder_rot_0',\n","                'RightShoulder_rot_1',\n","                'RightShoulder_rot_2',\n","                'RightShoulder_rot_3',\n","                'RightShoulder_rot_4',\n","                'RightShoulder_rot_5',\n","                'RightShoulder_rot_6',\n","                'RightShoulder_rot_7',\n","                'RightShoulder_rot_8',\n","                'RightArm_rot_0',\n","                'RightArm_rot_1',\n","                'RightArm_rot_2',\n","                'RightArm_rot_3',\n","                'RightArm_rot_4',\n","                'RightArm_rot_5',\n","                'RightArm_rot_6',\n","                'RightArm_rot_7',\n","                'RightArm_rot_8',\n","                'RightHand_rot_0',\n","                'RightHand_rot_1',\n","                'RightHand_rot_2',\n","                'RightHand_rot_3',\n","                'RightHand_rot_4',\n","                'RightHand_rot_5',\n","                'RightHand_rot_6',\n","                'RightHand_rot_7',\n","                'RightHand_rot_8',\n","                'RightForeArm_acc_0',\n","                'RightForeArm_acc_1',\n","                'RightForeArm_acc_2',]]\n","\n","output.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3HNdq-0GCxxy"},"source":["#load as torch for subject #10\n","x = torch.tensor(input.values)\n","y = torch.tensor(output.values)\n","\n","print(\"input data:\", x.shape, \"\\n\\n\", x)\n","\n","print(\"output data:\", y.shape, \"\\n\\n\", y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xuTIh3VjXtGG"},"source":["#HYPER_PARAMETERS\n","\n","# Number of features used as input. (Number of columns)\n","INPUT_SIZE = 12\n","# Number of previous time stamps taken into account.\n","SEQ_LENGTH = 2827\n","# Number of features in last hidden state ie. number of output time-\n","HIDDEN_SIZE = 15\n","# Number of stacked rnn layers.\n","NUM_LAYERS = 1\n","# Number of features in the output\n","OUTPUT_SIZE = 30\n","# We have total of 16962 rows in our input. \n","# We divide the input into 6 batches, with a sequence of 2827 rows.\n","BATCH_SIZE = 6\n","#learning rate\n","LEARNING_RATE = 0.003\n","#dropout parameter\n","DROPOUT_PROB=0.2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jwf91yu8YWMz"},"source":["# Initialize the Bidirectional RNN. \n","rnn = nn.RNN(input_size=INPUT_SIZE, hidden_size=HIDDEN_SIZE, num_layers = NUM_LAYERS, batch_first=True, bidirectional = True).double()\n","\n","# input size : (batch, seq_len, input_size)\n","inputs = x.view(BATCH_SIZE, SEQ_LENGTH, INPUT_SIZE)\n","print(\"input data:\", inputs.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rowhBADLfxbk"},"source":["# out shape = (batch, seq_len, num_directions * hidden_size)\n","# h_n shape  = (num_layers * num_directions, batch, hidden_size)\n","#output of the RNN from all timesteps from the last RNN layer,  hidden value from the last time-step of all RNN layers.\n","out, hidden = rnn(inputs.double()) \n","\n","print('\\nOutput: ', out.shape, '\\n', out)\n","print('\\nHidden: ', hidden.shape, '\\n', hidden)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HvH6jX4y3ebC"},"source":["**DATA LOADER**"]},{"cell_type":"markdown","metadata":{"id":"rzXrJWSX6VNO"},"source":["Train | Validation | Test Split"]},{"cell_type":"code","metadata":{"id":"Mq6DWKUs6RmK"},"source":["filenames = glob.glob(\"/content/drive/MyDrive/Neuromatch/MoVi Data/IMU_Subjects/preproc/*.csv\")\n","\n","train, test = train_test_split(filenames)\n","train, val = train_test_split(train)\n","\n","print(f' train size: {len(train)} files | validation size: {len(val)} files | test size: {len(test)} files')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wa0C0O2m3wPI"},"source":["\n","input = ['RightForeArm_rot_0',\n","         'RightForeArm_rot_1',\n","         'RightForeArm_rot_2',\n","         'RightForeArm_rot_3',\n","         'RightForeArm_rot_4',\n","         'RightForeArm_rot_5',\n","         'RightForeArm_rot_6',\n","         'RightForeArm_rot_7',\n","         'RightForeArm_rot_8',   \n","         'RightForeArm_acc_0',\n","         'RightForeArm_acc_1',\n","         'RightForeArm_acc_2',]\n","\n","output =    ['RightShoulder_rot_0',\n","            'RightShoulder_rot_1',\n","            'RightShoulder_rot_2',\n","            'RightShoulder_rot_3',\n","            'RightShoulder_rot_4',\n","            'RightShoulder_rot_5',\n","            'RightShoulder_rot_6',\n","            'RightShoulder_rot_7',\n","            'RightShoulder_rot_8',\n","\n","            'RightArm_rot_0',\n","            'RightArm_rot_1',\n","            'RightArm_rot_2',\n","            'RightArm_rot_3',\n","            'RightArm_rot_4',\n","            'RightArm_rot_5',\n","            'RightArm_rot_6',\n","            'RightArm_rot_7',\n","            'RightArm_rot_8',\n","\n","            'RightHand_rot_0',\n","            'RightHand_rot_1',\n","            'RightHand_rot_2',\n","            'RightHand_rot_3',\n","            'RightHand_rot_4',\n","            'RightHand_rot_5',\n","            'RightHand_rot_6',\n","            'RightHand_rot_7',\n","            'RightHand_rot_8',\n","\n","            'RightForeArm_acc_0',\n","            'RightForeArm_acc_1',\n","            'RightForeArm_acc_2']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r6vV0cTN3hTx"},"source":["class IMU_Dataset(Dataset):\n","    def __init__(self, dataDir,xCols, yCols, windowSize = 512, transform=None, target_transform=None):\n","        self.xCols = xCols\n","        self.yCols = yCols\n","        self.dataDir = dataDir\n","        self.windowSize = windowSize\n","        self.transform = transform\n","        self.target_transform = target_transform\n","        self.files = dataDir\n","        # pre-load all files\n","        dataSets = []\n","        for filenames in dataDir:\n","            samp_path = filenames\n","            # load the file\n","            dat = pd.read_csv(samp_path, index_col='Unnamed: 0')            \n","            dataSets.append(dat)\n","        self.dataSets = dataSets\n","\n","    def __len__(self):\n","        return len(self.files)\n","\n","    def __getitem__(self, idx):\n","        # get the file\n","        dat = self.dataSets[idx]\n","        # get random window in file\n","        starti = randint(0,dat.shape[0] - self.windowSize)\n","        endi = starti + self.windowSize\n","        dat = dat.iloc[starti:endi]\n","        #select variables\n","        x = torch.tensor(dat[self.xCols].values)\n","        y = torch.tensor(dat[self.yCols].values)\n","        \n","        # do optional transforms\n","        if self.transform:\n","            x = self.transform(x)\n","        if self.target_transform:\n","            y = self.target_transform(y)\n","\n","        if idx == self.__len__():\n","            raise IndexError            \n","        return x, y\n","\n","train_dataset = IMU_Dataset(train,input,output)\n","val_dataset = IMU_Dataset(val,input,output)\n","test_dataset = IMU_Dataset(test,input,output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UAXmLgNfuC3p"},"source":["# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"872PcUE_yOFV"},"source":["**Bidirectional Long Short-Term Memory Model**"]},{"cell_type":"code","metadata":{"id":"supIQXk0hLR8"},"source":["# Bidirectional LSTM \n","\n","class BiLSTM(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout_prob):\n","        super(BiLSTM, self).__init__()\n","\n","        # Defining the number of layers and the nodes in each layer\n","        self.hidden_size = hidden_size\n","        self.num_layers= num_layers\n","\n","        # LSTM layers\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob, bidirectional=True)\n","\n","        # Fully connected layer\n","        self.fc = nn.Linear(hidden_size*2, output_size) #*2 for bidirection    \n","    \n","    def forward(self, x):\n","        # Initializing hidden state for first input with zeros\n","        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).double().to(device) #*2 for bidirection\n","        #h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device) #*2 for bidirection\n","        #Initializing cell state for first input with zeros\n","        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device) #*2 for bidirection\n","\n","        # Forward propagation LSTM by passing in the input, hidden state, and cell state into the model\n","        out, (hn, cn) = self.lstm(x, (h0, c0)) # out: tensor of shape (batch_size, seq_length, hidden_size*2)\n","        \n","        # the outputs in the shape of (batch_size, seq_length, hidden_size), so that it can fit into the fully connected layer\n","        # Convert the final state to our desired output shape (batch_size, output_dim)\n","        out = self.fc(out)\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dKmQbMR0s_aC"},"source":["## **Training the Model**"]},{"cell_type":"code","metadata":{"id":"hU2uZWte59xj"},"source":["#HYPER-PARAMETERS\n","# Number of features used as input. (Number of columns)\n","INPUT_SIZE = 12\n","# Number of features in last hidden state ie. number of output time-\n","HIDDEN_SIZE = 15\n","# sequence length\n","SEQUENCE_LENGTH = 512\n","# Number of stacked rnn layers.\n","NUM_LAYERS = 1\n","# Number of features in the output\n","OUTPUT_SIZE = 30\n","# We have total of 16962 rows in our input. \n","# We divide the input into 6 batches, with a sequence of 2827 rows.\n","BATCH_SIZE = 6\n","#learning rate\n","LEARNING_RATE = 0.003\n","#dropout parameter\n","DROPOUT_PROB=0.2\n","#epochs\n","NUM_EPOCHS = 10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-NZ5Kydr6Gsv"},"source":["#Data Loader\n","trainLoader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle = True)\n","valLoader =  DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle = True)\n","testLoader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle = False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ImLjv8EUtFbl"},"source":["\n","#initializing the model\n","model = BiLSTM(INPUT_SIZE,HIDDEN_SIZE,NUM_LAYERS,OUTPUT_SIZE, DROPOUT_PROB).double().to(device)\n","# Loss and optimizer\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iAnzvjW72tNw"},"source":["# Train the model\n","total_step = len(trainLoader)\n","losses = []\n","for epoch in range(NUM_EPOCHS):\n","  running_loss = 0.0\n","  for i,(xBatch,yBatch) in enumerate(trainLoader):\n","      x_batch = xBatch.reshape(-1, SEQUENCE_LENGTH, INPUT_SIZE).to(device)\n","      target = yBatch.to(device)\n","\n","      #print(x_batch.shape)\n","      #print(y_batch.shape)\n","      \n","      # Forward pass\n","      outputs = model(x_batch.double())\n","      loss = criterion(outputs, target)\n","      \n","      # Backward and optimize\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","\n","      running_loss += loss.item() * x_batch.size(0)\n","  \n","  epoch_loss = running_loss / len(trainLoader)\n","  losses.append(epoch_loss)\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f2x3lVz0D299"},"source":["  # training_loss\n","  plt.plot(np.array(losses), label=\"Training loss\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wky6Xa0HP-G1"},"source":["#Test the model\n","with torch.no_grad():\n","  correct = 0\n","  total = 0\n","  predictions = []\n","  values = []\n","  for x_test, y_test in testLoader:\n","      x_test = x_test.reshape(-1, SEQUENCE_LENGTH, INPUT_SIZE).to(device)\n","      y_test = y_test.to(device)\n","      \n","      yhat = model(x_test)\n","      predictions.append(yhat.to(device).detach().numpy())\n","      values.append(y_test.to(device).detach().numpy())\n","      total += y_test.size(0)\n","\n","      #accuracy\n","      \n","\n","  #print('Test Accuracy of the model on the IMU Data: {} %'.format(100 * correct / total)) \n","  #print('Predictions: {} %'.format(predictions))\n"],"execution_count":null,"outputs":[]}]}